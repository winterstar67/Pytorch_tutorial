{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849ce145-1690-42c2-aa25-92f22732b5e1",
   "metadata": {},
   "source": [
    "## 3. BUILD THE NEURAL NETWORK\n",
    "https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2c3f1-8b5b-4935-a35b-199ec55ec267",
   "metadata": {},
   "source": [
    "Neural network는 많은 layers/modules로 이루어져 data에 대해서 연산을 한다. torch.nn은 사용자들만의 neural network를 만드는데에 필요한 building block들을 제공해준다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b532f879-2c96-4def-909f-be6698884b7d",
   "metadata": {},
   "source": [
    "이후 예제에서는 FashionMNIST 이미지들을 분류하는 neural network를 build해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702f9001-3fb5-4aca-813b-776797761166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision  import datasets, transforms # torchvision 관련해서는 https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2537bf22-9c2a-4508-9bd9-2056ec60737c",
   "metadata": {},
   "source": [
    "`-` Training을 위한 Device 설정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a46b816-d2f2-4c71-8783-7dfe4b25584b",
   "metadata": {},
   "source": [
    "가능하다면, GPU나 MPS와 같은 hardware accelerator에서 모델을 학습하고자 한다. 먼저 GPU나 MPS가 사용가능한지 보자.\n",
    "- hardware accelerator: hardware acceleration은 컴퓨팅에서 일부 기능을 CPU에서 구동하는 방식보다 빠르게 수행할 수 있는 하드웨어(GPU)의 사용을 말한다.\n",
    "\n",
    "- MPS: MPS(Multi-Process Service)는 다수의 프로세스가 동시에 단일 GPU에서 실행되도록 해주는 런타임 서비스다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4ff6d02-0f17-4a84-a903-0917e97eb046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available()\n",
    "         else \"mps\"\n",
    "         if torch.backends.mps.is_available()\n",
    "         else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f71903-71eb-409d-b693-eac3956df595",
   "metadata": {},
   "source": [
    "`-` Class 정의하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feeb40a-a192-45a7-ab07-439d1592a779",
   "metadata": {},
   "source": [
    "여기서 사용자는 nn.Module을 subclassing 함으로써 Neural Network를 정의할 수 있다. 그리고 neural network layers를 __init__를 통해서 initialize할 수 있다. 모든 nn.Module subclass는 forward method를 통해서 input 데이터에 대한 연산을 구현한다.\n",
    "- Subclassing 출처: https://velog.io/@yhlee9753/Java-%EC%9D%98-Generics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "776d3d28-7aa2-4dc4-84b2-9036cec3f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.flatten(x)\n",
    "            logits = self.linear_relu_stack(x)\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e6301-d1d3-4af2-a0b5-4978f815cb9e",
   "metadata": {},
   "source": [
    "이제 실제 input을 넣어 output이 나오는 동작이 되는 모델 class의 instance를 만들고, 모델의 구조를 print한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a1064d8-930a-40a3-9f2c-6a1205173384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fdcdb7-1fe2-427d-8a0a-10139928b5c8",
   "metadata": {},
   "source": [
    "## 모델 레이어들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e009444-f49d-4434-b0bd-d61b39c0f3a2",
   "metadata": {},
   "source": [
    "여기서 입력인 image는 아래와 같이 정의하고\n",
    "위의 `NeuralNetwork()`의 레이어를 작동과정과 함께 하나씩 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0abd0d9a-7b09-45c3-ab44-59948321d10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ec406d-e00b-41bc-8a67-de065463918d",
   "metadata": {},
   "source": [
    "`-` nn.Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933d809-7672-4989-8650-ec05be308aa1",
   "metadata": {},
   "source": [
    "위의 nn.Flatten는 2D인 28 by 28 image를 contiguose한 784길이의 array로 변환해준다. (단, batch dimension은 유지된다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a058c0a5-1b8d-48b0-ae7e-9b7598c24869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df337187-a60d-45e1-b8ee-67c247f70e74",
   "metadata": {},
   "source": [
    "`-` nn.Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a948447-1cb2-44c6-93f8-f60cd3e32814",
   "metadata": {},
   "source": [
    "nn.Linear는 nn.Linear에 저장된 weights와 bias 값을 가지고 input에 linear transformation을 적용한다.\n",
    "아래는 위에서 784길이로 변환한 input에 weights곱과 bias를 더하여 다음 layer에 20개의 output을 전달한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fa4f5b6-0673-4dde-8437-70214e87b66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features = 28*28, out_features = 20) # \n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066c95e5-ac28-4807-b624-484ec3bcdf35",
   "metadata": {},
   "source": [
    "`-` nn.ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da40dffa-3b71-4aca-a487-27b48bccc1c6",
   "metadata": {},
   "source": [
    "Non-linear 한 activation function인 ReLU이다. Linear가 linear transformation을 한 다음 여기에 nonlinearity를 적용해주는 역할을 한다. 이는 모델이 다양한 output을 내주도록 도와준다. 즉, 모델의 표현력이 증가한다.  \n",
    "- ReLU는 0미만 값은 0으로, 0이상의 값은 identity한 값이 나오도록 mapping해주는 함수.\n",
    "- ReLU이외에도 다른 non linear activation functions가 존재함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a549083-8a0a-4921-bdaa-1d0997f3f0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-0.3809, -0.5069, -0.6069,  0.3530, -0.1545,  0.2423,  0.0947, -0.0172,\n",
      "         -0.4334, -0.2419,  0.2784,  0.4531,  0.1922,  0.2756,  0.3507,  0.5308,\n",
      "         -0.3168,  0.3161, -0.2114, -0.2160],\n",
      "        [-0.6083, -0.2409, -0.5716,  0.4486, -0.0911,  0.2253, -0.1714, -0.1431,\n",
      "         -0.3146, -0.4192,  0.5556,  0.1647,  0.4398,  0.5658,  0.1044,  0.7514,\n",
      "         -0.1698,  0.0641,  0.1544, -0.2806],\n",
      "        [-0.4601, -0.5548, -0.1492,  0.6013,  0.3029,  0.4519, -0.0502, -0.1066,\n",
      "         -0.4079, -0.2639,  0.3063,  0.2510,  0.4217,  0.7640,  0.0640,  0.3840,\n",
      "         -0.3652,  0.1182,  0.1693, -0.4177]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.0000, 0.0000, 0.3530, 0.0000, 0.2423, 0.0947, 0.0000, 0.0000,\n",
      "         0.0000, 0.2784, 0.4531, 0.1922, 0.2756, 0.3507, 0.5308, 0.0000, 0.3161,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4486, 0.0000, 0.2253, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.5556, 0.1647, 0.4398, 0.5658, 0.1044, 0.7514, 0.0000, 0.0641,\n",
      "         0.1544, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.6013, 0.3029, 0.4519, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.3063, 0.2510, 0.4217, 0.7640, 0.0640, 0.3840, 0.0000, 0.1182,\n",
      "         0.1693, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a91ba4a-ffc1-47ff-985b-64d097c09650",
   "metadata": {},
   "source": [
    "`-` nn.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115e6792-9ac4-4762-b0b4-552233b59162",
   "metadata": {},
   "source": [
    "nn.Sequential은 모듈들을 담아, 담긴 순서대로 적용해주는 container 역할을 한다.\n",
    "예를들어, 아래의 nn.Sequential에 input을 넣으면 flatten, layer1, ReLU, Linear 순서로 input이 처리된다.  \n",
    "- 모듈 예: nn.Flatten, nn.Linear, nn.ReLU, ...\n",
    "\n",
    "nn.Sequential 모듈의 장점은, 위에서 flatten = nn.Flatten(), layer1 = nn.Linear() 와 같이 일일이 지정하던 것을 nn.Sequential이라는 모듈하나에 담아, 빠르게 network구성을 할 수 있다는 점이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80b616d6-0264-4ef0-9ec7-b481c1ba8ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20,10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d8b809-6157-4547-b0a3-db4b4c1b5bfa",
   "metadata": {},
   "source": [
    "`-` nn.Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec18282e-0cbe-49eb-a01b-6651ae71dcc1",
   "metadata": {},
   "source": [
    "마지막의 linear layer에서 나온 값의 범위를 [-infty, infty]에서 [0,1]로 변환해주는 역할을 한다. 이는 모델의 각 라벨에 대한 예측 확률로써 볼수도 있다.  \n",
    "- 여기서 dim 인자는 어떤 차원으로 softmax를 적용할지를 결정한다.\n",
    "\n",
    "아래 예시는 NeuralNetwork 모델의 출력값인 logits에 softmax를 적용하는 예시이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d3feffd-a09c-47ec-8898-7fe4650be6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0914, 0.0946, 0.1138, 0.0845, 0.1091, 0.1213, 0.0949, 0.0790, 0.1435,\n",
      "         0.0678],\n",
      "        [0.0949, 0.1163, 0.1055, 0.0772, 0.0987, 0.1056, 0.1103, 0.0756, 0.1462,\n",
      "         0.0697],\n",
      "        [0.0944, 0.1123, 0.1030, 0.0742, 0.1047, 0.1154, 0.0966, 0.0802, 0.1543,\n",
      "         0.0648]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1) # dim=1로 Softmax를 정의하는 함수를 정의\n",
    "pred_probab = softmax(logits) # 위에서 정의한 Softmax를 neural net의 output에 적용\n",
    "print(pred_probab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a42022-dbeb-49c2-83d1-77aa57d3b46c",
   "metadata": {},
   "source": [
    "## 모델 파라메터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681babc5-b02f-443a-be51-5fd63592cc60",
   "metadata": {},
   "source": [
    "Neural net안의 layer들에 파라메터들이 있다. 이들은 training과정에서 optimized되는데, nn.Module이 모든 파라메터들에 access할 수 있게 해준다 한다.  \n",
    "parameter에 접근하는 방법은  모델의 parameters() 혹은 named_parameters() methods를 사용하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aab58198-d187-4493-be87-53c615ce4fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0344,  0.0256,  0.0130,  ..., -0.0339,  0.0349, -0.0023],\n",
      "        [-0.0035,  0.0305,  0.0306,  ...,  0.0169,  0.0114, -0.0106]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0134,  0.0203], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0063, -0.0081,  0.0038,  ...,  0.0171, -0.0084,  0.0218],\n",
      "        [ 0.0184,  0.0190, -0.0368,  ...,  0.0164, -0.0380, -0.0320]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0007, -0.0049], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0422,  0.0217, -0.0024,  ...,  0.0067, -0.0228,  0.0253],\n",
      "        [-0.0360,  0.0043,  0.0393,  ..., -0.0223, -0.0144, -0.0316]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0009, 0.0032], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
