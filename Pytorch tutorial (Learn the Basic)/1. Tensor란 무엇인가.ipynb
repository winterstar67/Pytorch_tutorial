{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b162384-05e6-4adf-920e-2bba655d1ab6",
   "metadata": {},
   "source": [
    "# Pytorch tutorial 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849ce145-1690-42c2-aa25-92f22732b5e1",
   "metadata": {},
   "source": [
    "## 1. Tensor란 무엇인가.\n",
    "https://pytorch.org/tutorials/beginner/basics/tensor_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2c3f1-8b5b-4935-a35b-199ec55ec267",
   "metadata": {},
   "source": [
    "tensor는 list, tuple과 같은 하나의 Data structure이다.  \n",
    "파이토치에서는 tensor를 사용하여 model의 input, output, parameter를 encode하게 된다.  \n",
    "\n",
    "Pytorch의 특징:\n",
    "1. GPU에 올려서 실행할 수 있다.\n",
    "2. data를 카피할 필요도 없다.\n",
    "3. 자동 미분에 최적화 되어있다. (자동 미분관련하여 자세한 것은 [Autograd section 참고](https://pytorch.org/tutorials/beginner/basics/autograd_tutorial.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b2394a-5209-42d2-ab28-4abf862c09ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd84efc-ffcd-474c-a2e5-da56707fdda2",
   "metadata": {},
   "source": [
    "`-` tensor는 numpy array로부터 변환 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ff6d02-0f17-4a84-a903-0917e97eb046",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data) # List로부터 tensor 만들기\n",
    "np_array = np.array(x_data) # tensor로부터 ndarray 만들기\n",
    "x_np = torch.from_numpy(np_array) # ndarray로부터 tensor 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5470cd-68e2-4ec9-a83b-56a20472dad1",
   "metadata": {},
   "source": [
    "`-` shape와 datatype만 가져와 새로운 텐서를 만들수도 있다.  \n",
    "아래의 x_ones는 x_data의 shape와 datatype(**dtype**이라고도 한다.)을 가진 1로 이루어진 tensor를 생성한다.  \n",
    "x_rand는 x_data의 shape를 유지하면서 dtype이 torch.float인 랜덤 tensor들을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f88408a4-2337-4d65-b3f7-dfd57b68ce62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[0.4499, 0.4079],\n",
      "        [0.2207, 0.6538]])\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print(x_ones)\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(x_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2730b6-da81-4f9e-8c88-9a57b457059b",
   "metadata": {},
   "source": [
    "`-` tensor.shape에서 shape는 tensor의 dimension을 나타내는 tuple 데이터이다.  \n",
    "아래 결과는 shape를 지정하여 tensor를 생성하는 것을 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ef9216-947f-4c28-86fa-2ea2fec573e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.6251, 0.8828, 0.4285],\n",
      "        [0.4402, 0.0465, 0.5327]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991e5abe-419a-44c5-a603-12a320c0f8c7",
   "metadata": {},
   "source": [
    "`-` Tensor의 Attribute:  \n",
    "Tensor의 Attributes는 `shape`, `dtype(datatype)` 그리고 tensor가 저장되어있는 device를 나타내는 것이다.  \n",
    "아래는 torch.tensor에 귀속되어있는 attributes인 shape, dtypes, device의 출력 결과를 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebe4b66e-8fd0-4759-ab4b-8fd89fec7d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dbf16c-f3e8-453a-8bdc-e3cb00c47efd",
   "metadata": {},
   "source": [
    "`-` Tensor에서의 연산  \n",
    "Tensor에는 100가지가 넘는 연산자들이 존재한다.\n",
    "- 연산자 예: arithmetic, linear algebra, matrix manipulation(transposing, indexing, slicing), sampling 등등\n",
    "\n",
    "각각의 연산들은 GPU상에서 실행될 수 있다.\n",
    "- **보통 GPU위에서의 연산이 CPU에서의 연산보다 빠르다.**\n",
    "\n",
    "Default로, tensor를 생성하면 CPU위에서 생성된다. 따라서, GPU위에 tensor data를 올리려면 GPU가 사용 가능한지 확인한 후, `.to` method를 사용해서 올릴 수 있다.  \n",
    "- **device간에 크기가 큰 tensor를 copy하는 것은 시간과 메모리 상에서 expensive함을 명심하자!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b10ce705-8f3d-45a1-8152-22ce13a24af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3d6449-ab65-4ef2-870d-a3866b2eff27",
   "metadata": {},
   "source": [
    "`-` Tensor의 indexing을 살펴보자  \n",
    "- 첫 번째 row는 [0]으로 가르킨다.\n",
    "- 첫 번쨰 col은 [:,0]으로 가르킨다.\n",
    "- 마지막 column은 [..., -1]로 가르킨다.\n",
    "    - 여기서 ...은 `ELLIPSIS`라고 하는 객체이다. 이는, 다차원 데이터 배열을 쉽게 처리할 수 있도록 하는 것이다. 필자는 깊게 확인하지 않았는데, 예시 관련해서는 (https://whereisend.tistory.com/221) 참고."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d761b78-da3a-48bd-80db-c22def671537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row:  tensor([1., 1., 1., 1.])\n",
      "First column:  tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4) # 2차원 텐서에 대해서,\n",
    "print('First row: ',tensor[0]) # 첫 번째 row는 [0]으로 가르킨다.\n",
    "print('First column: ', tensor[:, 0]) # 첫 번쨰 col은 [:,0]으로 가르킨다\n",
    "print('Last column:', tensor[..., -1]) # 마지막 column은 [..., -1]로 가르킨다.\n",
    "tensor[:,1] = 0 # 이는 point wise와 같이 0을 넣으면 해당 column이 모두 0이 되는 것이다.\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adad1ce-cb42-440f-938e-f7ba7f048119",
   "metadata": {},
   "source": [
    "`-` Tensor 여러개 결합하기:  \n",
    "Tensor 여러개 결합은 cat이라는 concatenate 기능을 하는 함수를 통해서 결합할 수 있다.  \n",
    "아래에서는 tensor 데이터 여러개를 cat을 하고, 어떤 방향으로 결합할지는 dim이라는 인자로 지정하는데, 여기선 첫번쨰 차원에 대해서 결합하고자 dim=1를 사용했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "472c64df-adac-4f5e-9f1c-30451c629680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor,tensor,tensor],dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dfa1e2-e4b6-444a-99d6-4d2c868ac0fb",
   "metadata": {},
   "source": [
    "`-` 산술 연산  \n",
    "아래의 3개 연산은 모두 같은 matrix 곱을 나타낸다. 모두 결과는 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc09c739-76d1-465b-b19f-3562c916df91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = tensor @ tensor.T # matrix 곱을 의미한다.\n",
    "y2 = tensor.matmul(tensor.T) # 마찬가지로 matrix 곱을 의미한다.\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3) # 역시 matrix 곱이다. out인자의 역할은 잘 모르겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b87023-f33b-4ae7-a857-8faeaa4c5ea6",
   "metadata": {},
   "source": [
    "곱의 형태를 자세히 파악하기 위해 아래와 같이, row, column의 개수가 서로 다른 경우를 보자. 아래는 2 by 5 matrix이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a9b23ca-8f1d-4774-9bf6-96e4aa599e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[1,2,3,4,5],[6,7,8,9,10]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f40fa296-6182-4fd3-bdf7-2ff4d57f1405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n",
      "torch.Size([5, 2])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(tensor.shape), print(tensor.T.shape)\n",
    "y1 = tensor @ tensor.T\n",
    "print(y1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d0ff61-9fc3-4a2f-bb02-e402cd630830",
   "metadata": {},
   "source": [
    "- (m by n)  *  (n by m) 형식을 지켜야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77682dcf-2541-4ddc-a2e4-b2839985c240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "698fe7b0-f216-4c8c-a307-025ad3f60e7f",
   "metadata": {},
   "source": [
    "아래는 point-wise 곱, 즉 동일하게 대응되는 각각의 원소끼리의 연산을 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6096256e-8bdc-4e70-93ba-332a2e13fb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor,tensor,out=z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c30b2-c9f0-46ac-80ac-5f299787ea3a",
   "metadata": {},
   "source": [
    "`-` In-place operation:  \n",
    "In-place operation이란 주어진 tensor의 내용물을 copy없이 직접적으로 바꾸는 것을 의미한다.\n",
    "- In-place operation의 예시로 `+=`나 `*=`와 같은 것들이 있다고 한다. \n",
    "- 출처: https://discuss.pytorch.org/t/what-is-in-place-operation/16244\n",
    "\n",
    "Pytorch에서 In-place operation은 `_`를 뒤에 붙임으로써 사용된다 한다.\n",
    "- 예: `x.copy_(y)`, `x.t_()`는 x를 변경한다.\n",
    "\n",
    "아래의 예는 `tensor = ~~` 형태가 아님에도 함수 실행으로 tensor값을 바꾼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e1881af-0604-496f-adb8-a73cc93b4529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d49e97-4076-49bd-8146-ec4a70d2db49",
   "metadata": {},
   "source": [
    "`-` Numpy와의 연결점  \n",
    "`CPU 상에 있는 Tensor`와 Numpy는 이들의 memory location(?)을 공유할 수 있고, 하나를 바꾸면 다른 하나도 바뀐다 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61fd5ceb-a69c-4f96-b644-35a27e10c34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  tensor([1., 1., 1., 1., 1.])\n",
      "n:  [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(\"t: \",t)\n",
    "n = t.numpy()\n",
    "print(\"n: \",n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2cec0f-89cf-4b14-9695-bf2478da8227",
   "metadata": {},
   "source": [
    "이제 t라는 tensor를 바꾸면, t에서 파생된 numpy array인 n도 바뀌는 것을 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d701f0f-84ba-42df-83a0-5435f216c501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3446d5bc-bf97-41ca-b6aa-e9b943e9b734",
   "metadata": {},
   "source": [
    "`-` Numpy array에서 Tensor로의 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f31ab996-bcde-40e5-b84a-291b572367b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07a188-d9c6-4742-9a18-80e92585ca0e",
   "metadata": {},
   "source": [
    "이것도 마찬가지로, numpy array의 변화는 numpy array에서 나온 tensor 값 역시 변화시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d68e296-d984-4c91-a73e-224e2b7720b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n",
      "n: [3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
